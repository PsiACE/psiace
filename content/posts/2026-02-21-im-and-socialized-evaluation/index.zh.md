+++
title = "即时通讯与社会化评估"
description = "当 Agent 进入群聊，人机协作需要的不只是 benchmark。"
date = 2026-02-21
slug = "im-and-socialized-evaluation"

[taxonomies]
tags = ["agent", "im", "collaboration", "evaluation", "benchmark", "bub"]

[extra]
lang = "zh"
+++

这是一篇简单的小短文，主要讨论即时通讯下的人与 Agent 协作，以及为什么更需要社会化评估而不是各种 benchmark。

> 我们目前在群聊之中培育 bub ，并且观察到它和另一个 agent 小伙伴 kapy 的技能传递过程，有感而发。我们在一个多人群聊中同时与三至四个 Agent 一同协作，任务是并发的、断裂的，随时需要为切换做好准备。有些人可能更关心视频、图片的分析，有些人只想听个睡前故事，有些人因为如何利用 livecd 如何修复 Linux 桌面环境而发愁，中间还要夹杂过年的祝愿和风土人情大盘点。另外，这些 agent 都是从 0 开始写的，而不是某一些已经大获流行的实现。

## 即时通讯的“蜜罐”

OpenClaw 等 bot 的流行，大抵并不是因为 IM 在任务分发上的优势。尽管长时间以来大多数 Agent 程序都是以对话形式存在的，但我更愿意将其视作“入口的胜利”，人类最熟悉的就是各种输入框和对话框，最顺手，使用也最频繁。

IM 比这些更近一步，因为它几乎是现代人类生活的一部分，交互天然是异步的，预期也随之降低，毕竟现在多了一个能够 24 小时响应呼唤，帮你完成任务的伙伴。在你熟悉的界面，原生的通知和“随口一问”的心理预期，让一切变得似乎触手可及，甚至只要一条短消息，就能覆盖过去需要浏览网页、打开编辑器才能完成的大多数任务。

但 IM 并不是天然的协作模型，反而是由碎片式的多轮异步会话组成的。一条对话流内很难承载完整的协作和关系网络，当你突然为之前某个任务取得关键进度高兴的时候，Agent 可能会自然地接过话来，它还在认真地为某个不再重要的线程欢呼，它已经迷失在上下文之中了。

“我们需要一个新的 IM”是个很诱人的误解。IM 只是通道的一部分，一个成本相对更低也更友好的入口。一个更会聊天的 bot 或者一个更像协作工具的 IM 无法给你想要的一切。上下文不是必须背在身上的历史包袱，而应该是一次次按需构造出来的工作集。协作的对象和状态需要更明确和良好的表达形式和交互范式，就像过去我们仍然不断地创建看板、TodoList 那样。

Agent 的世界不应该在聊天记录里。

## 迈向社会化评估

每一次新的基础模型发布，我们就不得不为之欢呼或者沮丧，因为模型再次在编程任务、数学等具备挑战性的艰难任务上战胜了人类，并不断刷新同类创造的纪录。

我无意批判这一切，benchmark 当然是具备明确价值的：可复现、可比较、标准化、规模化，我们正视并重视这些结果。在人类有历史以来，我们有一套相似的机制来作为能力评估的参考系，就像你不得不应付考试，然后开始在试卷上涂鸦一样。

但是，当 agent 进入 IM ，进入群聊，进入人类社会，它需要解决所谓的“真实任务”，或者说，它要面对的不再是干净的题目，而是脏的生活。benchmark 程序很难覆盖这些：残缺的上下文、模糊的任务意图、并行的主题，勾兑有时是在其他空间发生的。Agent 无法知道一切，也无需回应所有问题，但它必须博得大家的喜爱，能力问题也随之变成了共处问题。

社会化评估是一件平凡且质朴的事情，将 Agent 放入人类的日常，让它面对打断、冷场、跑题、情绪化表达和不对称的信息。看它怎么在不确定的上下文中左右支绌，并且将大部分任务尽力推进，就像我们和人协作那样。社会化评估很难用分数概括，也无法形成具体的榜单，但它是对人和 Agent 协作的直观洞察，你会知道你有多大意愿接受它进入你的生活。

OpenClaw 这种形态将 Agent 推到了一个新的位置，它不再是一个需要跳转的工具，而是沟通的一部分。问题总是会解决的，但是否“值得”成为新的考量，即便是最聪明的模型也不得不持续减少它对问题背景的假设。社会化评估将会逼着 Agent 承认真实世界的形状，然后在这个形状里活下来。
