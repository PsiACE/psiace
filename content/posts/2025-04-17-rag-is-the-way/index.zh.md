+++
title = "RAG 没有捷径"
description = "检索、智能体、真实感：这三件事绑在一起，才是我们要面对的现代基础设施。"
date = 2025-04-17
slug = "rag-is-the-way"

[taxonomies]
tags = ["RAG", "Retrieval", "Agent", "Truth"]

[extra]
lang = "zh"
+++

去年我从数据库基础设施跳进 RAG 项目时，以为终于能摆脱底层细节，结果是另一种更复杂的基础设施扑面而来。RAG 看似应用层，其实处处是工程化的坑。

## 检索：不只是“找到”

传统搜索里，我们调索引、调排序，指标相对稳定。RAG 的检索要面对的是语义空间——向量近邻、模型偏差、上下文漂移。今天 QA 能命中“三季度发货策略”，明天可能因为语境不同完全跑偏。检索的目标从“找到哪条记录”变成“理解用户真正想说什么，并确保返回的语段能支撑后续推理”。

## Agent：别被名字骗了

大家给 Agent 起了很多酷炫的名字：规划代理、推理代理、工具代理……但它们大多还是条件语句堆出来的工作流。区别只是条件不是硬编码，而是 LLM 动态生成。重点不在“更智能”，而在“如何把工具、状态、反馈闭环结构化”。我们需要的是一个可观察、可替换的流程引擎，模型只是其中的决策组件。

## Grounding Truth：最后的锚点

没有扎实的事实校验，RAG 系统只是会讲好听故事的随机鹦鹉。Grounding 不是选配，而是价值锚定。你得持续补充可验证的知识底座，让领域专家参与反馈循环，设计清晰的“证据链”输出格式。否则，Agent 再聪明也只是在幻觉上做推理。

## 复杂性从哪里来

- **数据形态多样**：PDF、截图、音视频、传感器数据同时存在，且要保持语义一致。
- **一致性概念模糊**：知识会被实时更新，旧答案随时过期。你需要定义“足够新”“足够可信”的标准。
- **成本与体验拉扯**：检索准确度、上下文长度、延迟、推理深度，一环牵动一环。

这比建一个数据库、一个 API 难多了，但也更有意思。

## 为什么还要干

因为我们在重新定义“信息系统”：

- 让系统理解人的意图，而不是死背关键词；
- 让工具链能自我学习、自动拼装；
- 把抽象的语言推理和现实世界的事实连接起来。

这是一种新的基础设施：检索、智能体与真实感三元同构。谁能把这三者编排好，谁就掌握下一代知识系统的主动权。

所以，当别人问我为什么离开数据库领域去做 AI 应用时，我会说：“我没离开基础设施，我只是换了一种方式去构建它。”

现在，请允许我回去调向量量化、训几个不听话的 Agent，并确保文本切分策略不会把事实撕裂。这，就是日常的 RAG 工程。EOF
